{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efde77f2-6af3-4781-8597-89ecd3f41a52",
   "metadata": {
    "id": "efde77f2-6af3-4781-8597-89ecd3f41a52"
   },
   "source": [
    "# Qwen3 From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d41ae66-3a75-4d31-ad30-08951031ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d",
   "metadata": {
    "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a50f2a5-f09e-4046-99c9-c2dc4802de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "\n",
    "@dataclass()\n",
    "class Qwen3Config:\n",
    "    vocab_size=151936\n",
    "    hidden_size=1024\n",
    "    intermediate_size=3072\n",
    "    num_hidden_layers=28\n",
    "    num_attention_heads=16\n",
    "    num_key_value_heads=8\n",
    "    attention_bias=False\n",
    "    head_dim=128\n",
    "    hidden_act=\"silu\"\n",
    "    max_position_embeddings=40_960\n",
    "    rms_norm_eps=1e-6\n",
    "    tie_word_embeddings=False\n",
    "    rope_theta=10000.0\n",
    "    dtyp=torch.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4f13b-6173-4631-9ff0-0822099f437b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe14c4b-37b1-43fa-872b-b5e0e4ab19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3Model(nn.Module):\n",
    "    def __init__(self, config: Qwen3Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(config) for _ in range(config.num_hidden_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        \n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        # input_ids shape: [batch, seq_len]\n",
    "        \n",
    "        # [batch, input_ids, hidden_size]\n",
    "        x = self.embed_tokens(input_ids)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # shape not change\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # [batch, input_ids, hidden_size]\n",
    "        return x\n",
    "\n",
    "class Qwen3ForCausalLM(nn.Module):\n",
    "    def __init__(self, config: Qwen3Config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = Qwen3Model(config)\n",
    "        \n",
    "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # [batch, seq_len, hidden_size]\n",
    "        x = self.model(input_ids)\n",
    "\n",
    "        # [batch, seq_len, vocab_size]\n",
    "        x = self.lm_head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0469f-d06e-46cd-824c-226c840d72cb",
   "metadata": {},
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc158161-df8b-4bc0-a5bb-f3f6f25c80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: Qwen3Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layernorm = nn.RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "\n",
    "        self.self_attn = Qwen3Attention(config)\n",
    "\n",
    "        self.post_attention_layernorm = nn.RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "\n",
    "        self.mlp = Qwen3MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.input_layernorm(x)\n",
    "        x = self.self_attn(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.post_attention_layernorm(x)\n",
    "        x = self.mlp(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41fa82-4f1c-47b5-b760-71a4b83ed8aa",
   "metadata": {},
   "source": [
    "### Qwen3Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab063b4-04cd-4604-b4de-94723fda27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3Attention(nn.Module):\n",
    "    def __init__(self, config: Qwen3Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.q_proj = nn.Linear(config.hidden_size, config.num_attention_heads * config.head_dim, bias=config.attention_bias)\n",
    "        self.k_proj = nn.Linear(config.hidden_size, config.num_key_value_heads * config.head_dim, bias=config.attention_bias)\n",
    "        self.v_proj = nn.Linear(config.hidden_size, config.num_key_value_heads * config.head_dim, bias=config.attention_bias)\n",
    "\n",
    "        self.o_proj = nn.Linear(config.num_attention_heads * config.head_dim, config.hidden_size, bias=config.attention_bias)\n",
    "\n",
    "        self.q_norm = nn.RMSNorm(config.head_dim, eps=config.rms_norm_eps)\n",
    "        self.k_norm = nn.RMSNorm(config.head_dim, eps=config.rms_norm_eps)\n",
    "\n",
    "        self.scale = self.config.head_dim**-0.5\n",
    "\n",
    "        self.rotary_embedding = RotaryEmbedding(config.head_dim, config.max_position_embeddings, config.rope_theta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, seqlen, _ = x.shape\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "\n",
    "        q = q.view(batch, seqlen, self.config.num_attention_heads, self.config.head_dim)\n",
    "        k = k.view(batch, seqlen, self.config.num_key_value_heads, self.config.head_dim)\n",
    "        v = v.view(batch, seqlen, self.config.num_key_value_heads, self.config.head_dim)\n",
    "\n",
    "        # [batch, qhead, seqlen, head_dim]\n",
    "        q = q.transpose(1, 2)\n",
    "        # [batch, kvhead, seqlen, head_dim]\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        \n",
    "        q = self.q_norm(q)\n",
    "        k = self.k_norm(k)\n",
    "\n",
    "        \n",
    "        q = self.rotary_embedding(q)\n",
    "        k = self.rotary_embedding(k)\n",
    "\n",
    "\n",
    "        group_size = self.config.num_attention_heads // self.config.num_key_value_heads\n",
    "        \n",
    "        \"\"\"\n",
    "        [1,2,3].repeat_interleave(2, dim=0) => [1, 1, 2, 2, 3, 3]\n",
    "        \"\"\"\n",
    "        # [batch, kv_head * group_size, seqlen, head_dim]\n",
    "        k = k.repeat_interleave(group_size, dim=1)\n",
    "        v = v.repeat_interleave(group_size, dim=1)\n",
    "\n",
    "\n",
    "        scores = q @ k.transpose(-2, -1)\n",
    "\n",
    "        \"\"\"\n",
    "        0 1 1 1 1\n",
    "        0 0 1 1 1\n",
    "        0 0 0 1 1\n",
    "        0 0 0 0 1\n",
    "        0 0 0 0 0\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(seqlen, seqlen, device=x.device, dtype=torch.bool), diagonal=1)\n",
    "        scores = scores.masked_fill(mask, -torch.inf)\n",
    "        scores = scores * self.scale\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # [batch, q_head, seqlen, head_dim]\n",
    "        o = weights @ v\n",
    "\n",
    "        # [batch, seqlen, q_head, head_dim]\n",
    "        o = o.transpose(1, 2)\n",
    "\n",
    "        # [batch, seqlen,hidden_size]\n",
    "        o = o.flatten(2)\n",
    "\n",
    "        out = self.o_proj(o)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54387bbb-0c55-4c93-89c4-7eab804aedff",
   "metadata": {},
   "source": [
    "## Rotary Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d9f34e-4746-4ec5-ae21-e8a8d56c97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim: int,\n",
    "            max_position_embeddings: int,\n",
    "            rope_theta: float,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.rope_theta = rope_theta\n",
    "\n",
    "        # 1 / theta^(0, 2, 4, ..., dim-2) / dim\n",
    "        inv_freq = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float) / dim))\n",
    "\n",
    "        # position: [max_position_embeddings]\n",
    "        position = torch.arange(max_position_embeddings, dtype=torch.float)\n",
    "\n",
    "        # freqs: [max_position_embeddings, dim/2]\n",
    "        freqs = torch.einsum(\"i,j->ij\", position, inv_freq)\n",
    "\n",
    "        # cos: [max_position_embeddings, dim/2]\n",
    "        self.register_buffer(\"cos_cached\", torch.cos(freqs))\n",
    "        # sin: [max_position_embeddings, dim/2]\n",
    "        self.register_buffer(\"sin_cached\", torch.sin(freqs))\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [batch, heads, seqlen, head_dim]\n",
    "        seqlen = x.size(2)\n",
    "    \n",
    "        cos = self.cos_cached[:seqlen, :]\n",
    "        sin = self.sin_cached[:seqlen, :]\n",
    "        cos = cos.unsqueeze(0).unsqueeze(0)  # [1, 1, seqlen, dim/2]\n",
    "        sin = sin.unsqueeze(0).unsqueeze(0)  # [1, 1, seqlen, dim/2]\n",
    "    \n",
    "        x1, x2 = torch.chunk(x.float(), 2, dim=-1)\n",
    "        x_rotated = torch.zeros_like(x)\n",
    "        x_rotated[..., 0::2] = x1 * cos - x2 * sin\n",
    "        x_rotated[..., 1::2] = x2 * cos + x1 * sin\n",
    "        return x_rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acece40f-d493-4dc0-a44a-2bd93da14af5",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397f0070-4b73-49c1-9938-6663b1a0dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3MLP(nn.Module):\n",
    "    def __init__(self, config: Qwen3Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gate_proj = nn.Linear(config.hidden_size, config.intermediate_size, bias=False)\n",
    "        self.up_proj = nn.Linear(config.hidden_size, config.intermediate_size, bias=False)\n",
    "        self.down_proj = nn.Linear(config.intermediate_size, config.hidden_size, bias=False)\n",
    "        self.act_fn = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.gate_proj(x)\n",
    "        x2 = self.up_proj(x)\n",
    "        x = self.act_fn(x1) * x2\n",
    "        x = self.down_proj(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbfa940-3201-47a9-b958-644821a39e51",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1eee2b2-1b25-4a90-80ad-e13bba26fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = Qwen3ForCausalLM(Qwen3Config())\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429cba7-dc54-4ee8-bd60-34f99dc57f83",
   "metadata": {},
   "source": [
    "## Load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2ce705-3381-4e5d-9af3-df0b6328c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from safetensors import safe_open\n",
    "import glob\n",
    "\n",
    "huggingface_model_dir = '~/huggingface/Qwen3-0.6B/'\n",
    "\n",
    "def load_weight(huggingface_model_dir, model):\n",
    "    params = dict(model.named_parameters())\n",
    "    \n",
    "    for file in glob.glob(os.path.join(path, \"*.safetensors\")):\n",
    "        with safe_open(file, \"pt\", \"cpu\") as f:\n",
    "            for name in f.keys():\n",
    "                weight = f.get_tensor(name)\n",
    "                assert name in params, f\"Parameter {name} not found in model\"\n",
    "                param = params[name]\n",
    "                param.data.copy_(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b8642c4-46a8-403c-9f31-9072e361f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.expanduser(\"~/huggingface/Qwen3-0.6B/\")\n",
    "load_weight(path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f4035-fc37-4a69-9aa2-76ab5b8786d9",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c626a7-6981-44fe-9604-0fc6f825f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "\n",
    "qwen3_tokenizer = tokenizers.Tokenizer.from_file(path + \"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e711d4b2-5260-478b-8c1b-d3fc0cd36777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9707, 11, 1879]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen3_tokenizer.encode(\"Hello, world\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afa6d348-e300-413f-a857-3d7a58e648cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, world'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen3_tokenizer.decode(qwen3_tokenizer.encode(\"Hello, world\").ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030fb6d-b0dc-486f-8ced-2c8be371f194",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74bed6e9-df35-497f-8323-3a256e27707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_chat_template(prompt: str, enable_think: bool = False) -> str:\n",
    "    prompt = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    if enable_think is False:\n",
    "        prompt += \"<think>\\n\\n</think>\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f85f4812-a325-4f5d-8443-c026c2d12308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model: Qwen3ForCausalLM, tokenizer, prompt: str, enable_think=True, max_new_tokens=256):\n",
    "    prompt = apply_chat_template(prompt, enable_think)\n",
    "    tokens = qwen3_tokenizer.encode(prompt).ids\n",
    "    eos_token = tokenizer.encode(\"<|im_end|>\").ids[0]\n",
    "    # [batch, seqlen]\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        # [batch, seqlen, vocob_size]\n",
    "        logits = model(tokens)\n",
    "\n",
    "        # [batch, 1]\n",
    "        next_token = torch.argmax(logits[:,-1], dim=-1, keepdim=True)\n",
    "        tokens = torch.cat([tokens, next_token], dim=-1)\n",
    "\n",
    "        token_id = next_token.squeeze(0).tolist()\n",
    "        print(tokenizer.decode(token_id), end=\"\", flush=True)\n",
    "        \n",
    "        if token_id[0] == eos_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b900efd-4ffa-4282-ad84-fd855aed2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking about the meaning of life. First, I need to consider different perspectives. The user might be looking for a philosophical answer, or perhaps they're interested in the meaning of life in a more personal or spiritual sense.\n",
      "\n",
      "I should mention that the meaning of life can vary depending on individual beliefs, cultural values, and personal experiences. It's a deeply personal question, and the answer can vary widely.\n",
      "\n",
      "Also, it's important to note that the meaning of life is not something that can be found in a single book or article. It's a question that can be answered in many different ways, depending on the individual's beliefs and values.\n",
      "\n",
      "In conclusion, the meaning of life is a deeply personal and subjective question. It can vary widely depending on individual beliefs, cultural values, and personal experiences.\n",
      "</think>\n",
      "\n",
      "The meaning of life is a deeply personal and subjective question. It can vary widely depending on individual beliefs, cultural values, and personal experiences. Ultimately, the meaning of life is not something that can be found in a single book or article. It's a question that can be answered in many different ways, depending on the individual's beliefs and values."
     ]
    }
   ],
   "source": [
    "generate(model, qwen3_tokenizer, \"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "903de99f-ad26-45c8-bdaf-3e9dcc084254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question of what is the meaning of life is a deeply personal and philosophical question. It is a universal question that has been asked by people for centuries.\n",
      "\n",
      "The meaning of life can vary greatly depending on individual beliefs, values, and experiences. Some people believe that life has a purpose, such as achieving personal goals, contributing to society, or finding meaning in life.\n",
      "\n",
      "Ultimately, the meaning of life is a deeply personal question that can be answered in many different ways."
     ]
    }
   ],
   "source": [
    "generate(model, qwen3_tokenizer, 'What is the meaning of life?', enable_think=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87db9b9-0117-4f0d-9e0a-96feb077588f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
